#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
app.py
- Chainlit ã®ãƒãƒ£ãƒƒãƒˆUIã¨ã€/code_searchãƒ»/query ã‚’æä¾›ã™ã‚‹ FastAPI ã‚’åŒä¸€ãƒ—ãƒ­ã‚»ã‚¹ã§èµ·å‹•ã€‚
- LLM ã¯ Ollamaï¼ˆåˆ¥PCã§ã‚‚å¯ã€ç’°å¢ƒå¤‰æ•° OLLAMA_BASE_URLï¼‰ã€‚
- åŸ‹ã‚è¾¼ã¿ã¯ HuggingFaceEmbeddingï¼ˆOpenAIã‚­ãƒ¼ä¸è¦ï¼‰ã€‚ingest.py ã¨åŒã˜ EMBED_MODEL ã‚’ä½¿ã†ã“ã¨ã€‚

ã€è¶…ã–ã£ãã‚Šæµã‚Œï¼ˆåˆå¿ƒè€…å‘ã‘ï¼‰ã€‘
1) Qdrantï¼ˆãƒ™ã‚¯ã‚¿DBï¼‰ã« ingest.py ã§æŠ•å…¥æ¸ˆã¿ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ã£ã¦ã€è³ªå•æ–‡ã‚’æ„å‘³æ¤œç´¢ï¼ˆRAGã®å–å¾—ï¼‰
2) å–å¾—ã—ãŸã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’å†ãƒ©ãƒ³ã‚¯ï¼ˆCrossEncoderï¼‰ã—ã¦ã€ã‚ˆã‚Šé–¢é€£ã®é«˜ã„ä¸Šä½ã ã‘æ®‹ã™
3) ãã‚Œã‚‰ã‚’æ ¹æ‹ ã¨ã—ã¦ LLMï¼ˆOllamaï¼‰ã«å›ç­”æ–‡ã®ç”Ÿæˆã‚’ä¾é ¼ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ ¹æ‹ ã‚’è©°ã‚è¾¼ã‚€ï¼‰
4) Chat UIï¼ˆChainlitï¼‰ã«å›ç­”ï¼‹å¼•ç”¨ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«/è¡Œç•ªå·ï¼‰ã‚’è¡¨ç¤º

ã€å¿…è¦ãªç’°å¢ƒå¤‰æ•°ï¼ˆ.env æ¨å¥¨ï¼‰ã€‘
  OLLAMA_BASE_URL=http://host.docker.internal:11434   # ã¾ãŸã¯åˆ¥PCã®IP:11434ï¼ˆDockerå†…ã‹ã‚‰ãƒ›ã‚¹ãƒˆã®Ollamaã¸ï¼‰
  OLLAMA_MODEL=llama3:13b
  EMBED_MODEL=BAAI/bge-m3
  QDRANT_URL=http://qdrant:6333
  QDRANT_COLLECTION=codebase
  API_PORT=8001
  LOG_LEVEL=INFO    # DEBUG/INFO/WARN/ERROR

ãƒ’ãƒ³ãƒˆ: ã¾ãš ingest.py ã‚’å®Ÿè¡Œã—ã¦ Qdrant ã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥â†’ æ¬¡ã« app.py ã‚’èµ·å‹•ã™ã‚‹ã¨è³ªå•ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
"""

import os
import re
import fnmatch
import shutil
import json
import subprocess
import threading
import logging
from pathlib import Path
from typing import List, Optional, Literal, Tuple

# -------- ãƒ­ã‚°è¨­å®š --------
LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO").upper()
logging.basicConfig(level=getattr(logging, LOG_LEVEL, logging.INFO),
                    format="%(asctime)s | %(levelname)-7s | %(message)s")
log = logging.getLogger("app")

# -------- Chainlit --------
import chainlit as cl

# -------- LlamaIndex / Qdrant åˆæœŸåŒ– --------
from llama_index.core import Settings, VectorStoreIndex, StorageContext
from llama_index.llms.ollama import Ollama
from llama_index.vector_stores.qdrant import QdrantVectorStore
from qdrant_client import QdrantClient

# åŸ‹ã‚è¾¼ã¿ï¼ˆOpenAIæ—¢å®šã‚’é¿ã‘ã‚‹ãŸã‚ã«å¿…ãšæ˜ç¤ºè¨­å®šï¼‰
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# å†ãƒ©ãƒ³ã‚¯ï¼ˆCPUã§ã‚‚å¯ï¼‰
from sentence_transformers import CrossEncoder

# -------- FastAPIï¼ˆ/code_search, /queryï¼‰ --------
from typing import Any
from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn

# -------- è¨­å®šå€¤ --------
SRC_ROOT = Path(__file__).parent.resolve() / "src_repos"
API_PORT = int(os.environ.get("API_PORT", "8001"))

QDRANT_URL = os.environ.get("QDRANT_URL", "http://qdrant:6333")
COLLECTION = os.environ.get("QDRANT_COLLECTION", "codebase")

EMBED_MODEL = os.environ.get("EMBED_MODEL", "BAAI/bge-m3")
RERANK_MODEL = os.environ.get("RERANK_MODEL", "BAAI/bge-reranker-v2-m3")

# LLM (Ollama)
# ãƒã‚¤ãƒ³ãƒˆ: OpenAI API ã¯ä½¿ã‚ãšãƒ­ãƒ¼ã‚«ãƒ«/åˆ¥PCã® Ollama ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚
#           base_url ã¯ Docker ã‹ã‚‰è¦‹ãŸ Ollama ã®å ´æ‰€ï¼ˆhost.docker.internal ãªã©ï¼‰ã«åˆã‚ã›ã¾ã™ã€‚
Settings.llm = Ollama(
    model=os.environ.get("OLLAMA_MODEL", "llama3:13b"),
    base_url=os.environ.get("OLLAMA_BASE_URL", "http://localhost:11434"),
    request_timeout=120.0
)

# Embeddingï¼ˆOpenAIã®æ—¢å®šã‚’å›é¿ï¼‰
# ãƒã‚¤ãƒ³ãƒˆ: ingest.py ã¨åŒã˜åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«åã‚’å¿…ãšæŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆæ¤œç´¢å´ã¨ç™»éŒ²å´ã§æƒãˆã‚‹ï¼‰ã€‚
Settings.embed_model = HuggingFaceEmbedding(model_name=EMBED_MODEL)
log.info(f"Embedding model = {EMBED_MODEL}")

# Qdrant æ¥ç¶šï¼†Index
# ãƒã‚¤ãƒ³ãƒˆ: æ—¢ã« Qdrant ã«å…¥ã£ã¦ã„ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚
qclient = QdrantClient(url=QDRANT_URL)
vstore = QdrantVectorStore(client=qclient, collection_name=COLLECTION)
storage = StorageContext.from_defaults(vector_store=vstore)
index = VectorStoreIndex.from_vector_store(vstore)

# å†ãƒ©ãƒ³ã‚«ãƒ¼ï¼ˆæœ€åˆã®ãƒ­ãƒ¼ãƒ‰ã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰
# ãƒã‚¤ãƒ³ãƒˆ: CrossEncoder ã¯ã€Œè³ªå•Ã—ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€ã‚’ãƒšã‚¢ã§è©•ä¾¡ã—ã¦é–¢é€£åº¦ã‚’å†è¨ˆç®—ã—ã¾ã™ã€‚
log.info(f"Loading reranker: {RERANK_MODEL} ...")
reranker = CrossEncoder(RERANK_MODEL)
log.info("Reranker ready.")

# ======== å…±æœ‰ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ========
def rerank_nodes(query: str, nodes: List[Any], top_k: int = 6) -> List[Any]:
    """æ„å‘³æ¤œç´¢ã®åˆæœŸçµæœã‚’ CrossEncoder ã§ä¸¦ã¹æ›¿ãˆã€ä¸Šä½ top_k ã‚’è¿”ã™ã€‚

    åˆæœŸã® `nodes` ã¯ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã§è¿‘ã„é †ã§ã™ãŒã€
    CrossEncoderï¼ˆå†ãƒ©ãƒ³ã‚¯ï¼‰ã§ã€Œæœ¬å½“ã«è³ªå•ã«ç­”ãˆã‚‹ã®ã«è‰¯ã„ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‹ã€ã‚’å†è©•ä¾¡ã—ã¾ã™ã€‚
    """
    if not nodes:
        return []
    texts, unwrapped = [], []
    for n in nodes:
        node = getattr(n, "node", n)
        unwrapped.append(node)
        texts.append(node.get_text() if hasattr(node, "get_text") else getattr(node, "text", ""))

    pairs = [[query, t] for t in texts]
    try:
        # ç’°å¢ƒå¤‰æ•°ã§ãƒãƒƒãƒã‚µã‚¤ã‚º/ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã®æœ‰ç„¡ã‚’èª¿æ•´å¯èƒ½ã«
        batch = int(os.environ.get("RERANK_BATCH", "16"))
        apply_softmax = os.environ.get("RERANK_SOFTMAX", "0") == "1"

        scores = reranker.predict(
            pairs,
            batch_size=batch,
            show_progress_bar=False,
            apply_softmax=apply_softmax,
        )
    except Exception as e:
        log.warning(f"Rerank failed, fallback original order: {e}")
        return unwrapped[:top_k]

    ranked = sorted(zip(unwrapped, scores), key=lambda x: float(x[1]), reverse=True)
    return [n for n, _ in ranked[:top_k]]

def build_prompt(question: str, nodes: List[Any]) -> str:
    """LLM ã«æ¸¡ã™æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

    - æ ¹æ‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’ [repo/path Lstart-Lend] + æœ¬æ–‡ ã§åˆ—æŒ™
    - å›ç­”ã¯ã€Œæ ¹æ‹ ã®ã¿ã§ã€è¡Œã†ã‚ˆã†ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§å¼·åˆ¶
    """
    context_blocks = []
    for n in nodes:
        m = getattr(n, "metadata", {}) or {}
        header = f"[{m.get('repo','')}/{m.get('path','')} L{m.get('start_line','?')}-{m.get('end_line','?')}]"
        text = n.get_text() if hasattr(n, "get_text") else getattr(n, "text", "")
        context_blocks.append(f"{header}\n{text}")

    sysinst = (
        "ã‚ãªãŸã¯ã‚³ãƒ¼ãƒ‰è§£æã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æ ¹æ‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®ã¿ã‚’ç”¨ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
        "æ ¹æ‹ ãŒä¸ååˆ†ãªã‚‰ã€ä¸æ˜ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚æ¨æ¸¬ã‚„å¤–éƒ¨çŸ¥è­˜ã¯ç¦æ­¢ã§ã™ã€‚"
    )
    prompt = f"{sysinst}\n\nã€è³ªå•ã€‘\n{question}\n\nã€æ ¹æ‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€‘\n" + "\n\n".join(context_blocks)
    return prompt

def run_query_pipeline(question: str, top_k_vec: int = 30, top_k_final: int = 6) -> Tuple[str, List[dict]]:
    """è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®ä¸€é€£ã®å‡¦ç†ï¼ˆRAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼‰ã€‚

    1) ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆsimilarity_top_k=top_k_vecï¼‰ã§ç²—ãå€™è£œã‚’æ‹¾ã†
    2) CrossEncoderï¼ˆå†ãƒ©ãƒ³ã‚¯ï¼‰ã§ top_k_final ã¾ã§å³é¸
    3) æ ¹æ‹ ä»˜ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦ã¦ LLM ã¸
    4) å¼•ç”¨æƒ…å ±ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«/è¡Œç•ªå·ï¼‰ã‚‚çµ„ã¿ç«‹ã¦ã¦è¿”ã™

    æˆ»ã‚Šå€¤: (LLMå›ç­”ãƒ†ã‚­ã‚¹ãƒˆ, å¼•ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®é…åˆ—)
    """
    retriever = index.as_retriever(similarity_top_k=top_k_vec)
    try:
        nodes = retriever.retrieve(question)
    except Exception as e:
        log.error(f"Retriever error: {e}")
        nodes = []

    # NodeWithScore -> å†ãƒ©ãƒ³ã‚¯
    top_nodes = rerank_nodes(question, nodes, top_k=top_k_final)

    # LLM ã¸
    prompt = build_prompt(question, top_nodes)
    try:
        resp = Settings.llm.complete(prompt)
        answer = resp.text
    except Exception as e:
        log.error(f"LLM error: {e}")
        answer = f"[LLM error] {e}"

    citations = gather_citations(top_nodes)
    return answer, citations

# ======== FastAPI: /code_search & /query ========

EXT_MAP = {
  "c": [".c", ".h"],
  "cpp": [".cpp", ".cc", ".cxx", ".hpp", ".hh", ".hxx"],
  "java": [".java"],
  "rust": [".rs"],
  "javascript": [".js", ".mjs", ".cjs", ".jsx"],
  "typescript": [".ts", ".tsx", ".mts", ".cts", ".d.ts"],
  "vue": [".vue"],
}

class CodeSearchReq(BaseModel):
    # /code_search ç”¨ã®å…¥åŠ›ã€‚literalï¼ˆå®Œå…¨ä¸€è‡´ï¼‰ã‹ regexï¼ˆæ­£è¦è¡¨ç¾ï¼‰ã‚’é¸ã¹ã¾ã™ã€‚
    query: str
    kind: Literal["literal", "regex"] = "literal"
    lang: Optional[List[str]] = None
    path_globs: Optional[List[str]] = None
    case_sensitive: bool = True
    max_results: int = 200
    before_after_lines: int = 3

class CodeSearchHit(BaseModel):
    # /code_search ã®1ä»¶åˆ†ã®ãƒ’ãƒƒãƒˆçµæœï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯å‰å¾Œè¡Œä»˜ãï¼‰ã€‚
    repo: str
    path: str
    lang: str
    start_line: int
    end_line: int
    preview: str

class QueryReq(BaseModel):
    # /query ç”¨ã®å…¥åŠ›ã€‚top_k ã¯æœ€çµ‚çš„ã«ä½•ä»¶ã®æ ¹æ‹ ã‚’ä½¿ã†ã‹ã€‚
    question: str
    top_k: int = 6

app = FastAPI(title="RAG API (/code_search, /query)")

def _lang_of(path: Path) -> str:
    ext = path.suffix.lower()
    for k, arr in EXT_MAP.items():
        if ext in arr:
            return k
    return "unknown"

def _iter_files(root: Path, langs: Optional[List[str]], globs: Optional[List[str]]):
    """å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ—æŒ™ã€‚

    - `langs` æŒ‡å®šæ™‚ã¯æ‹¡å¼µå­ã§ãƒ•ã‚£ãƒ«ã‚¿
    - `.git` ã‚„ `node_modules` ãªã©ã¯é™¤å¤–
    - `globs` æŒ‡å®šæ™‚ã¯ãƒ‘ã‚¹ã®ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã§ã•ã‚‰ã«çµã‚Šè¾¼ã¿
    """
    allow_ext = None
    if langs:
        allow_ext = set(e for L in langs for e in EXT_MAP.get(L, []))
    for p in root.rglob("*"):
        if not p.is_file():
            continue
        rel = p.relative_to(root)
        if any(part in {".git","node_modules","build","target"} for part in rel.parts):
            continue
        if allow_ext and p.suffix.lower() not in allow_ext:
            continue
        if globs and not any(fnmatch.fnmatch(str(rel).replace("\\","/"), g) for g in globs):
            continue
        yield p

def _search_with_ripgrep(req: CodeSearchReq) -> List[CodeSearchHit]:
    """rgï¼ˆripgrepï¼‰ãŒä½¿ãˆã‚‹å ´åˆã¯ã“ã¡ã‚‰ã‚’å„ªå…ˆã—ã¦é«˜é€Ÿæ¤œç´¢ã€‚

    JSON å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å‰å¾Œè¡Œã¤ãã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ•´å½¢ã—ã¾ã™ã€‚
    ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ç’°å¢ƒã§ã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã—ã€Python å®Ÿè£…ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    """
    hits: List[CodeSearchHit] = []
    if shutil.which("rg") is None:
        return hits
    cmd = ["rg", "--json", "-n", f"-C{req.before_after_lines}"]
    if req.kind == "literal":
        cmd.append("-F")
    if not req.case_sensitive:
        cmd.append("-i")
    if req.path_globs:
        for g in req.path_globs:
            cmd += ["-g", g]
    cmd.append(req.query)
    cmd.append(str(SRC_ROOT))

    try:
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        path_cache = {}
        count = 0
        for line in proc.stdout:  # type: ignore
            try:
                obj = json.loads(line)
            except Exception:
                continue
            if obj.get("type") != "match":
                continue
            data = obj.get("data", {})
            path_text = data.get("path", {}).get("text")
            if not path_text:
                continue
            abs_path = Path(path_text)
            if SRC_ROOT not in abs_path.resolve().parents and abs_path.resolve() != SRC_ROOT.resolve():
                continue
            rel = abs_path.relative_to(SRC_ROOT)
            repo = rel.parts[0] if len(rel.parts) > 1 else ""
            lang = _lang_of(abs_path)
            try:
                if abs_path not in path_cache:
                    path_cache[abs_path] = abs_path.read_text(encoding="utf-8", errors="ignore").splitlines()
                lines = path_cache[abs_path]
                lnum = data.get("line_number", 1)
            except Exception:
                continue
            start = max(1, lnum - req.before_after_lines)
            end = min(len(lines), lnum + req.before_after_lines)
            snippet = "\n".join(f"{i:>5}: {lines[i-1]}" for i in range(start, end+1))
            hits.append(CodeSearchHit(
                repo=repo, path=str(rel), lang=lang,
                start_line=start, end_line=end, preview=snippet
            ))
            count += 1
            if count >= req.max_results:
                break
        proc.terminate()
    except Exception as e:
        log.warning(f"ripgrep failed: {e}")
    return hits

def _search_with_python(req: CodeSearchReq) -> List[CodeSearchHit]:
    """rg ãŒãªã„ã¨ãã®ç´”Pythonç‰ˆæ¤œç´¢ï¼ˆé…ã„ãŒä¾å­˜ãªã—ï¼‰ã€‚"""
    hits: List[CodeSearchHit] = []
    flags = 0 if req.case_sensitive else re.IGNORECASE
    rx = re.compile(req.query if req.kind == "regex" else re.escape(req.query), flags)
    count = 0
    for p in _iter_files(SRC_ROOT, req.lang, req.path_globs):
        try:
            lines = p.read_text(encoding="utf-8", errors="ignore").splitlines()
        except Exception:
            continue
        for i, line in enumerate(lines, start=1):
            if rx.search(line):
                start = max(1, i - req.before_after_lines)
                end = min(len(lines), i + req.before_after_lines)
                snippet = "\n".join(f"{j:>5}: {lines[j-1]}" for j in range(start, end+1))
                rel = p.relative_to(SRC_ROOT)
                repo = rel.parts[0] if len(rel.parts) > 1 else ""
                hits.append(CodeSearchHit(
                    repo=repo, path=str(rel), lang=_lang_of(p),
                    start_line=start, end_line=end, preview=snippet
                ))
                count += 1
                if count >= req.max_results:
                    return hits
    return hits

@app.post("/code_search")
def code_search(req: CodeSearchReq):
    """ã‚³ãƒ¼ãƒ‰å…¨æ–‡æ¤œç´¢APIã€‚rg ãŒç„¡ã‘ã‚Œã° Python ã§ä»£æ›¿ã€‚"""
    hits = _search_with_ripgrep(req)
    if not hits:
        hits = _search_with_python(req)
    return {"hits": [h.model_dump() for h in hits]}

@app.post("/query")
def query(req: QueryReq):
    """RAG + å†ãƒ©ãƒ³ã‚¯ + LLMã§å›ç­”ã‚’ç”Ÿæˆã™ã‚‹APIã€‚"""
    answer, cits = run_query_pipeline(req.question, top_k_vec=30, top_k_final=req.top_k)
    return {"answer": answer, "citations": cits}

def start_api_server():
    log.info(f"Starting FastAPI on 0.0.0.0:{API_PORT}")
    uvicorn.run(app, host="0.0.0.0", port=API_PORT, log_level="info")

# ======== Chainlit ãƒãƒ³ãƒ‰ãƒ© ========

WELCOME = """ã‚ˆã†ã“ã ğŸ‘‹

ã“ã®ãƒœãƒƒãƒˆã¯ã€Œæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®åˆ†æãƒ»èª¿æŸ»ã€ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
- ğŸ§  RAGï¼ˆæ„å‘³æ¤œç´¢ï¼‰ã§é–¢é€£ã‚³ãƒ¼ãƒ‰ã‚’é›†ã‚ã€å›ç­”ã¯å¿…ãšæ ¹æ‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆä»˜ã
- ğŸ” å³å¯†æ¤œç´¢ãŒå¿…è¦ãªã¨ãã¯ `/search` ã‚³ãƒãƒ³ãƒ‰ï¼ˆä¾‹: `/search regex:"\\bstrcpy\\(" lang:c path:"src/**"`ï¼‰
"""

@cl.on_chat_start
async def on_start():
    await cl.Message(content=WELCOME).send()

@cl.on_message
async def on_message(message):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦ RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å›ã—ã¦å›ç­”ã‚’è¿”ã—ã¾ã™ã€‚
    # é‡ã„å‡¦ç†ã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ƒãŒã—ã€Chainlit ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é€”ä¸­ã§ã€Œæ¤œç´¢ä¸­â€¦ã€ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    # message ã‚’æ–‡å­—åˆ—ã«
    if isinstance(message, str):
        text = message.strip()
    else:
        text = (getattr(message, "content", "") or "").strip()

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€
    msg = cl.Message(content="æ¤œç´¢ä¸­â€¦ï¼ˆRAG + re-rank å®Ÿè¡Œä¸­ï¼‰")
    await msg.send()

    # é‡ã„å‡¦ç†ã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§
    answer, cits = await cl.make_async(run_query_pipeline)(text, top_k_vec=30, top_k_final=6)

    refs = "\n".join(
        f"- `{c['repo']}/{c['path']}` L{c['startLine']}-{c['endLine']}" for c in cits
    ) or "(no references)"
    md = f"{answer}\n\n**References**\n{refs}"

    # Chainlitã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³å·®ã«å¯¾å¿œï¼ˆupdate ã®å‘¼ã³æ–¹ãŒç•°ãªã‚‹ãŸã‚ä¸¡å¯¾å¿œï¼‰
    try:
        # æ–°ã—ã‚ã®API: contentã‚’ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã«ä»£å…¥ã—ã¦ã‹ã‚‰update()
        msg.content = md
        await msg.update()
    except TypeError:
        # æ—§API: update(content=...) ãŒä½¿ãˆã‚‹
        await msg.update(content=md)

# è¿½åŠ ï¼šapp.py ã«è²¼ã‚Šä»˜ã‘ï¼ˆrun_query_pipeline ã‚ˆã‚Šä¸Šã«ç½®ãï¼‰
from typing import Any

def gather_citations(nodes: list[Any]) -> list[dict]:
    """
    NodeWithScore / TextNode ã‹ã‚‰ã€å‚ç…§ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦è¿”ã™ã€‚
    - è¡¨ç¤ºç”¨ã« repo/path ã¨è¡Œç•ªå·ã‚’å–ã‚Šå‡ºã—ã¦ã€Chainlit ã«æ¸¡ã›ã‚‹å½¢ã«æ•´å½¢ã—ã¾ã™ã€‚
    run_query_pipeline() ã®æˆ»ã‚Šå€¤ã«ãã®ã¾ã¾è¼‰ã›ã¾ã™ã€‚
    """
    citations: list[dict] = []
    for n in nodes:
        node = getattr(n, "node", n)  # NodeWithScore ãªã‚‰ .nodeã€ãã†ã§ãªã‘ã‚Œã°ãã®ã¾ã¾
        m = getattr(node, "metadata", {}) or {}
        citations.append({
            "repo": m.get("repo", ""),
            "path": m.get("path", ""),
            "lang": m.get("lang", ""),
            "startLine": m.get("start_line", m.get("startLine", "?")),
            "endLine": m.get("end_line", m.get("endLine", "?")),
        })
    return citations

# ======== ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆï¼šFastAPI ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§èµ·å‹• ========
if os.environ.get("DISABLE_CODE_SEARCH_API", "0") != "1":
    th = threading.Thread(target=start_api_server, daemon=True)
    th.start()
